*   PHP 5 的内存回收原理？
> php5.2及之前采用的是引用计数算法进行内存回收的，其原理为为每个内存都对象zval分配一个计数器(refcount_gc)，初始值为1，之后每有一个新的变量引用此内存地址，计数器加1，反则减1，为0时销毁内存对象并回收其占用的内存。
> php5.3及之后为了解决循环引用造成的内存泄露问题，在原来引用计数算法的基础上，引进了同步回收算法，当根缓冲区满了之后才进行内存回收处理，通过模拟删除、模拟恢复操作之后，清空缓冲区的的所有根，然后销魂所有refcount为0的zval,并回收其内存。这种同步算法可将内存泄露控制一个阈值之内，阈值由缓冲区大小有关。

*   请详细描述ZendMM的工作原理。
> ZendMM是php的内存管理逻辑，ZMM基于libc的基础上自己实现了一套内存管理机制，简单说就是在os、libc与应用之间新增了一个中间层，专门对内存进行管理，ZMM基于libc的内存管理方法重写的内存的释放和获取的e方法，在程序运行时，内存的释放和获取并不是直接和OS进行交互的，而是通过ZMM来实现，ZMM在向OS申请内存时不是需要多少申请多少，而是申请一块相对来说比较大的内存，保存在缓冲区内，下次申请直接从缓冲区内获取分配内存，同样在释放内存时，内存也不是立马回到os中，而是在zmm的缓冲区中标识该内存为可用状态，因此产生了很多的内存碎片，看起来内存使用情况很多，在php5.2及之前，由于没有很好的垃圾回收机制，所以不适合用来做守护进程长期运行。在php5.3及之后，到现在的php7，引入了引用计数的同步回收算法，新的GC机制。
> 如果需要完全禁用ZendMM，则可以使用USE_ZEND_ALLOC=0env var 启动PHP 。这样，每次对ZendMM API的调用（如emalloc()）都将定向到libc调用，并且ZendMM将被禁用。这在调试内存时特别有用。

*   PHP 7 的垃圾回收和 PHP 5 有什么区别？
> PHP的垃圾回收机制以引用计数为基础
> PHP5.2与PHP5.3的垃圾回收机制有很大的区别，5.2基于引用计数算法进行垃圾回收，引用计数为0时即触发回收机制，再着对于循环引用无法触发回收机制，refcount回不到0，造成内存泄露，因此php5.2及之前的版本无法胜任守护进程长期运行的工作。
> PHP5.3及之后为了解决循环引用造成的内存泄露问题，在原来引用计数算法的基础上，引进了同步回收算法，新增了一个疑似垃圾的根缓冲区，当根缓冲区满了之后自动进行内存回收处理，通过模拟删除、模拟恢复操作之后，清空缓冲区的的所有根，然后销毁所有refcount为0的zval,并回收其内存。这种同步算法可将内存泄露控制一个阈值之内，阈值由缓冲区大小有关，因此解决了php5.2的循环引用的问题。
> PHP7的垃圾回收机制与PHP5.3差别不大，PHP7主要区别在于对zval结构体进行了优化。
> 简单的数据类型不需要单独分配内存，也不需要计数，减少了大量的内存分配和释放操作，避免了内存分配的头部冗余。
> 复杂数据类型引用计数由数值自己本身存储，因此可以和非zval结构的数据共享。

*   描述一下 cli 模式下的几个生命周期？

>*    请求开始阶段
>*    模块初始化阶段（MINIT）
>*    模块激活阶段（RINT）
>*    请求结束阶段
>*    停用模块[RSHUTDOWN]
>*    关闭模块[MSHUTDOWN]

*   php-fpm 运行机制？
> 首先启动一个master进程和多个worker进程
> master进程负责监听端口、cgi、php环境初始化、子进程状态，接受来自web server服务器的请求
> worker进程负责处理php请求，每个进程内部嵌入了一个php解释器，是php代码真正执行的地方

*   php-fpm 的生命周期
>fpm通过sapi接口与php进程交互

>1. 模块初始化阶段（module init）：
    这个阶段主要进行php框架、zend引擎的初始化操作。这个阶段一般是在SAPI启动时执行一次，对于FPM而言，就是在fpm的master进行启动时执行的。php加载每个扩展的代码并调用其模块初始化例程（MINIT），进行一些模块所需变量的申请,内存分配等。
>2. 请求初始化阶段（request init）：
    当一个页面请求发生时，在请求处理前都会经历的一个阶段。对于fpm而言，是在worker进程accept一个请求并读取、解析完请求数据后的一个阶段。在这个阶段内，SAPI层将控制权交给PHP层，PHP初始化本次请求执行脚本所需的环境变量。
>3. php脚本执行阶段
    php代码解析执行的过程。Zend引擎接管控制权，将php脚本代码编译成opcodes并顺次执行
>4. 请求结束阶段（request shutdown）：
    请求处理完后就进入了结束阶段，PHP就会启动清理程序。这个阶段，将flush输出内容、发送http响应内容等，然后它会按顺序调用各个模块的RSHUTDOWN方法。 RSHUTDOWN用以清除程序运行时产生的符号表，也就是对每个变量调用unset函数。
>5. 模块关闭阶段（module shutdown）：
该阶段在SAPI关闭时执行，与模块初始化阶段对应，这个阶段主要是进行资源的清理、php各模块的关闭操作，同时，将回调各扩展的module shutdown钩子函数。这是发生在所有请求都已经结束之后，例如关闭fpm的操作。（这个是对于CGI和CLI等SAPI，没有“下一个请求”，所以SAPI立刻开始关闭。）

*  php-fpm创建进程方式，各自的优缺点
>1. static 模式（静态模式）
static 模式始终会保持一个固定数量的子进程，这个数量由 pm.max_children 的配置决定
>2. dynamic 模式（动态模式）
子进程的数量是动态变化的，启动时，会生成固定数量的子进程，可以理解为最小子进程数，通过 pm.statr_servers 配置决定，而最大子进程数则由 pm.max_children 控制，子进程数会在 pm.start_servers ~ pm.max_children 范围内波动，另外，闲置的子进程数还可以由 pm.min_spare_servers 和 pm.max_spare_servers 两个配置参数控制。总结：闲置的子进程也可以有最小数目和最大数目，而如果闲置的子进程超过 pm.max_spare_servers, 则会被杀死。
>3. ondemand 模式（动态需求模式）
这种模式和 dynamic 模式相反。因为这种模式把内存放在第一位，每个闲置进程在持续闲置了 pm.process_idle_timeout 秒后就会被杀死，因为这种模式，到了服务器低峰期的时候，内存就会降下来，如果服务器长时间没有请求，就只有一个主进程。其弊端是，遇到高峰期或者 pm.process_idle_timeout 设置太小，无法避免服务器频繁创建进程的问题。

*  常见魔术方法和函数
>* __construct()，类的构造函数
>* __destruct()，类的析构函数
>* __call()，在对象中调用一个不可访问方法时调用
>* __callStatic()，用静态方式中调用一个不可访问方法时调用
>* __get()，获得一个类的成员变量时调用
>* __set()，设置一个类的成员变量时调用
>* __isset()，当对不可访问属性调用isset()或empty()时调用
>* __unset()，当对不可访问属性调用unset()时被调用。
>* __sleep()，执行serialize()时，先会调用这个函数
>* __wakeup()，执行unserialize()时，先会调用这个函数
>* __toString()，类被当成字符串时的回应方法
>* __invoke()，调用函数的方式调用一个对象时的回应方法
>* __set_state()，调用var_export()导出类时，此静态方法会被调用。
>* __clone()，当对象复制完成时调用
>* __autoload()，尝试加载未定义的类
>* __debugInfo()，打印所需调试信息
>* [100 个最常用的 PHP 函数](https://segmentfault.com/a/1190000018674933)

*  php 数组遍历为什么能保证有序
>* 使用映射表于bucket实现有序性，映射表于bucket内存紧挨着，左边是映射表，右边是bucket
>* 映射表保存了hash之后的值（转为负数），bucket按照插入顺序保存了插入的值，遍历的时候便利bucket就保持了有序性
> [剖析PHP数组的有序性](https://segmentfault.com/a/1190000019964143)

*   php-fpm 模式下，kill -9 master-pid，会怎么样？kill matser-pid 呢？
> 

*   内存分配流程？为什么要这么设计？
> PHP有自己的内存管理逻辑，ZMM。大致逻辑为首先检查缓存，如果命中则使用缓存中的内存块，否则在堆层（heap）从小块内存，大块内存，剩余内存中查找合适内存，如果有则返回分配好的内存地址，否则向OS申请一块内存并返回。
> 这么设计的原因
> 避免直接向os申请内存，减少分配和释放操作，减轻os负担

*   GC 的出现是为了解决什么问题？什么时候会触发 GC？说下大概流程
> 自动处理内存资源的分配与释放，解决内存泄露的问题
> php version&gt;=5.3中当疑似垃圾根缓冲区满的时候，自动触发GC机制。GC机制见上面的回答。

*   `nginx` 和 `php-fpm` 的通信机制
> uninx socket/tcp socket

*   fast-cgi 和 cgi 区别
> cgi（`common gateway interface`）是一种协议,它规定了要传那些数据并以什么格式传递给后方处理这个请求的协议。
> `fast-cgi`是用来提高cgi程序性能的，使用`master`进程来初始化执行环境，加载配置文件，同时启动多个`worder`进程来处理请求，避免了重复的初始化环境和解析配置文件，提高了效率

*   `php-fpm` 创建 `worker` 进程的规则是什么？不同场景下怎么选择？
> `dynamic、static、ondemand`
> 默认为`dynamic`
> static 固定数量的worker，推荐内存较大的服务器进行配置
> dynamic 动态分配，推荐内存较少或者vps上使用，具体可采用 `内存/20~30M`得出

*   php 和 mysql 的通信机制？长链接和短链接啥区别？怎么实现的？连接池要怎么实现？
> 长链接、短链接、连接池
> 长链接、短链接的区别
> 连接池实现

#### 
[<svg class="octicon octicon-link" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg>](#%E7%BB%93%E6%9E%84)结构

*   PHP 7 中对zVal做了哪些修改？
_以php 7.0.0为例，后续版本还在不断的优化更新_
> 优化了zval结构体的大小，在64位系统下只需要16个字节，主要为2个部分，value和扩充字段，而扩充字段氛围u1和u2两个部分，u1为type info，u2为各种辅助字段。
> 调整了zval的类型，数量达到了17种，其中新增了’引用’（is_reference）这种新的类型，同时将is_bool拆分为is_true和is_false
> 调整了zval的引用计数规则，对于在zval的value字段能保存下来的值，就不再进行引用计数了，这部分类型有`is_long,is_double,is_null,is_false,is_true`，对于复杂类型，如is_array,is_object，如果放不下其值（value只有1个指针大小，8个字节），那么value用来保存一个指针，这个指针指向具体的值，引用计数也作用于这个值上，而不在作用于zval上了。
> **这样做有几个优点：**
> 不再需要分配的内存的简单类型的值，避免了内存分配的头部冗余，及减少了不必要的内存分配和释放
> 避免了两次引用计数，像对象，在php5的时候它有两套引用计数，一个是zval的，另一个是obj本身的计数
> 复杂的类型的值都内嵌了引用计数，因此它们可以不依赖zval机制而进行共享
> 新增了是否需要引用的标志位（`IS_TYPE_REFCOUNTED`）

*   PHP 7 中哪些变量类型在栈，哪些变量类型在堆？变量在栈会有什么优势？PHP 7是如何让变量新建在栈的？
> 简单类型如整型，布尔，浮点存放在栈，复杂类型如数组、对象、可变字符串存放在堆，但对应的名称在栈。
> 变量在栈的优势是互相隔离，各自运行。栈内存更新快，内存可直接存取。
> 新建的局部简单类型变量就默认在栈。
> 栈：`LIFO pop,push,top`

*   php 里的数组是怎么实现的？
> HashTable+双向链表
> 参考资料 [php数组实现原理](https://blog.csdn.net/mysteryflower/article/details/101549756)

*   详细描述PHP中HashMap的结构是如何实现的？
> HashMap的基本思想，使用哈希函数将复杂的键值转换为整数，然后整数可用作普通c数组的偏移量。但是问题在于2^32或者2^64的个数比字符串的数目（无穷多个）的数目少的多，这样就会出现两个不同的键的hash值一样的情况，PHP5在PHP7在处理这种冲突上是不一样的，都采用连接法方式处理冲突，但在具体实现上有着一些区别，php7在php5的基础上优化了HashMap结构体，去掉很多冗余的内存消耗。

php5中的处理方式

> 将具有相同哈希的所有元素（bucket）存储在一个双向链表中，这些元素都是单独分配内存的，同时还有另外一个双向链表，用于保存数组中元素的顺序。
> 查找时，将计算哈希值，然后遍历可能的链接列表，直到找到匹配的条目。
> 以上结构是低效的:
> Bukets需要分开分配，每次额外需要分配8/16个字节，比较冗余。分开分配意味着这些buckets会分布在内存空间的不同地址中，这对缓存不友好（`cache-unfriendly`）。
> zval也需要分开分配，除了上述的问题，其次这也会带来额外的头开销冗余（header overhead）。同时还要在每个bucket中保存一个指向zval结构的指针。
> 双向链表中的每个bucket需要4个指针用于链表的连接，这回带来16/32字节的开销，遍历这种链表也是对缓存不友好的。

php7中的处理方式

> arData保存了所有的buckets(也就是数组的元素)，这个数组被分配的内存大小为2的幂次方，arData直接包含bucket结构，避免了过多的法分配和释放（`alloc/frees`）内存操作，同时避免了头开销冗余（header overhead）和额外的指针分配内存。
> 关于元素的顺序，arData数组以插入的顺序保存元素。当某元素被删除时，只是将删除元素zval类型标记为`IS_UNDEF`。相比php5中的双向链表的方式，这里的每个bucket只需要保存两个指针，这两个指针的开销为8/16字节。同时对于缓存是友好的（cache-friendly）。不足的地方是arData很少会缩小，除非进行显式操作。

*   下面代码中，在PHP 7下， $a 和 $b、$c、$d 分别指向什么zVal结构？

*   $d 被修改的时候，PHP 7 / PHP 5 的内部分别会有哪些操作？

    ```php
    $a = 'string';
    $b = &$a;
    $c = &$b;
    $d = $b;
    $d = 'to';

*   JIT 是做了哪些优化，从而对PHP的速度有不少提升？
    > JIT可直接将源码编译成机器码，省去了中间字节码（opcode）的转换，再由php解释器转换成机器码（native code）的过程，大幅提升了执行效率。

    #### 
    [<svg class="octicon octicon-link" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg>](#%E5%AD%97%E7%AC%A6%E4%B8%B2%E6%93%8D%E4%BD%9C)字符串操作

*   strtr 和 str_replace 有什么区别，两者分别用在什么场景下？
    > strtr是字符串转换 str_replace是字符串替换
>     strtr是基于原字符串 str_replace是基于替换后的字符串
>     strtr在使用的时候有两种形式分别为：
>     `1.strtr(string, from, to); 2.strtr(string, ['from'=&gt;'to']); `
>     推荐使用第2种用法，因为第1种用法有些特别注意的地方，
>     一是from和to替换的规则是逐个转换,并不是整体替换，可看到下面的例子中you的o被替换成了O,显示不是我们想要的结果
    <div class="highlight highlight-text-html-php position-relative overflow-auto" data-snippet-clipboard-copy-content='// I lOve yOu
    strtr("I Love you","Lo","lO"); '><pre><span class="pl-c">// I lOve yOu</span>
    <span class="pl-en">strtr</span>(<span class="pl-s">"I Love you"</span>,<span class="pl-s">"Lo"</span>,<span class="pl-s">"lO"</span>); </pre></div>
    > 二是当from的长度小于to时，下面的例子中A并没有出现，you中的o被替换成了O
    <div class="highlight highlight-text-html-php position-relative overflow-auto" data-snippet-clipboard-copy-content='// I lOvEs yOu
    strtr("I Loves you","Love","lOvEA"); '><pre><span class="pl-c">// I lOvEs yOu</span>
    <span class="pl-en">strtr</span>(<span class="pl-s">"I Loves you"</span>,<span class="pl-s">"Love"</span>,<span class="pl-s">"lOvEA"</span>); </pre></div>

*   strtr的程序是如何实现的？
    > 两种方式
    
    > 第1种情况下，将from和to的每个字符利用hashtable一一对应起来，逐个完成字符串的转换。
    > 第2种情况下，首先使用key到主字符串中根据kmp算法查找key的位置（O(n)），如果找到则使用value进行替换（替换m次），效率为O(n*m)


*   字符串在手册中介绍，「PHP的字符串是二进制安全的」，这句话怎么理解，为什么是二进制安全？
> 不会因为\0而中断字符串
> [摘自知乎问题答案](https://www.zhihu.com/question/28705562)
> c中的strlen函数就不算是binary safe的，因为它依赖于特殊的字符'\0'来判断字符串是否结束，所以对于字符串str = "1234\0123"来说，`strlen(str)=4`
> 而在php中，strlen函数是binary safe的，因为它不会对任何字符（包括'\0'）进行特殊解释，所以在php中，`strlen(str)=8`
> 所以，我理解的二进制安全的意思是：只关心二进制化的字符串,不关心具体格式.只会严格的按照二进制的数据存取。不会妄图已某种特殊格式解析数据。

*   字符串连接符.，在内核中有哪些操作？多次.连接，是否会造成内存碎片过多？
> 分配新的内存地址和释放旧的内存。
> 多次使用.连接字符串会频繁的alloc/frees，造成更多的内存碎片。

#### 
[<svg class="octicon octicon-link" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg>](#%E5%A4%9A%E7%BA%BF%E7%A8%8B)多线程

*   PHP中创建多线程、多进程有哪些方式？互斥信号该如何实现？
> Pecl中有个扩展`pthreads`提供了多线程特性
> 多进程可使用`proc_open/popen`函数
> pthreads的`Mutex`类可以操作互斥信号；

*   PHP中使用多线程和多进程分别有哪些优缺点？
> 线程比较轻量级，通过共享内存变量可实现线程间通信，但读写变量时存在同步问题，需要加锁。
> 开销大量线程会比进程更耗资源。
> 线程发生致命错误会导致整个进程崩溃。
> 进程相对线程来说更稳定，利用进程间通信（IPC）也可以实现数据共享。
> 共享内存也需要加锁，存在同步、死锁问题。
> 单个线程的退出不会导致整个进程退出，父进程还有机会重建流程。
> PHP原生使用的就是多进程模式

*   线上环境中，PHP进程偶尔会卡死（死锁），请问如何检测本质问题？
> 通过`ps aux | grep php-cgi` 查看进程启动时间，定位启动时间较早的进程
> 通过`lsof -p [pid] `查看进程都干了些啥
> 进一步分析进程 `strace -p [pid]`
> 通过`gdb attach [pid]`分析获取调用堆栈
> 或使用 [Swoole Tracker](https://www.swoole-cloud.com/tracker/index)

#### 
[<svg class="octicon octicon-link" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg>](#%E7%AE%A1%E9%81%93)管道

*   Laravel的中间件的顺序执行，是如何实现的？
> 中间件核心类`Illuminate\Routing\Pipeline`，其中的`then()`方法利用了`array_reduce()`函数，将反转后(`array_reverse()`)的中间件数组分别以闭包的形式暂存到一个类似栈的结构中，这个结构我们可以理解为一个大的闭包，里面嵌套的包含了所有需要执行的中间件闭包，执行的时候顺序为从最外层开始往里面执行（后进先出），最后执行`Initial`。

*   实现管道的makeFn函数
<div class="highlight highlight-text-html-php position-relative overflow-auto" data-snippet-clipboard-copy-content="function pipe($input, $list) {
    $fn = makeFn($list);
    return $fn($input);
}
$r = pipe(0, [$a, $b, $c]);
echo $r;
//$a, $b, $c 类似于
$a = function($input, $next) {
    $input++;
    $output = $next($input);
    return $output;
};
function makeFn($list){
    //请实现
    return function($input) use($list) {
        foreach($list as $item){
            $item($input, $item);
        }
    }
}"><pre><span class="pl-k">function</span> <span class="pl-en">pipe</span>(<span class="pl-s1"><span class="pl-c1">$</span>input</span>, <span class="pl-s1"><span class="pl-c1">$</span>list</span>) {
    <span class="pl-s1"><span class="pl-c1">$</span>fn</span> = <span class="pl-en">makeFn</span>(<span class="pl-s1"><span class="pl-c1">$</span>list</span>);
    <span class="pl-k">return</span> <span class="pl-s1"><span class="pl-c1">$</span>fn</span>(<span class="pl-s1"><span class="pl-c1">$</span>input</span>);
}
<span class="pl-s1"><span class="pl-c1">$</span>r</span> = <span class="pl-en">pipe</span>(<span class="pl-c1">0</span>, [<span class="pl-s1"><span class="pl-c1">$</span>a</span>, <span class="pl-s1"><span class="pl-c1">$</span>b</span>, <span class="pl-s1"><span class="pl-c1">$</span>c</span>]);
<span class="pl-k">echo</span> <span class="pl-s1"><span class="pl-c1">$</span>r</span>;
<span class="pl-c">//$a, $b, $c 类似于</span>
<span class="pl-s1"><span class="pl-c1">$</span>a</span> = <span class="pl-k">function</span>(<span class="pl-s1"><span class="pl-c1">$</span>input</span>, <span class="pl-s1"><span class="pl-c1">$</span>next</span>) {
    <span class="pl-s1"><span class="pl-c1">$</span>input</span>++;
    <span class="pl-s1"><span class="pl-c1">$</span>output</span> = <span class="pl-s1"><span class="pl-c1">$</span>next</span>(<span class="pl-s1"><span class="pl-c1">$</span>input</span>);
    <span class="pl-k">return</span> <span class="pl-s1"><span class="pl-c1">$</span>output</span>;
};
<span class="pl-k">function</span> <span class="pl-en">makeFn</span>(<span class="pl-s1"><span class="pl-c1">$</span>list</span>){
    <span class="pl-c">//请实现</span>
    <span class="pl-k">return</span> <span class="pl-k">function</span>(<span class="pl-s1"><span class="pl-c1">$</span>input</span>) <span class="pl-k">use</span>(<span class="pl-s1"><span class="pl-c1">$</span>list</span>) {
        <span class="pl-k">foreach</span>(<span class="pl-s1"><span class="pl-c1">$</span>list</span> <span class="pl-k">as</span> <span class="pl-s1"><span class="pl-c1">$</span>item</span>){
            <span class="pl-s1"><span class="pl-c1">$</span>item</span>(<span class="pl-s1"><span class="pl-c1">$</span>input</span>, <span class="pl-s1"><span class="pl-c1">$</span>item</span>);
        }
    }
}</pre></div>

#### 
[<svg class="octicon octicon-link" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg>](#%E5%86%85%E5%AD%98%E4%BC%98%E5%8C%96)内存优化

*   使用cUrl下载大文件时，占用内存太大，有没比较优化的方式？
> 使用cUrl下载时，文件在存入本地磁盘之前会将文件先放在内存中，文件很大时会占用内存，比较优化的方式是使用流下载，利用`CURLOPT_FILE`选项传递一个可写的文件流给到cUrl。

*   PHP 上传大文件（比如：2 GiB的视频），需要修改php.ini的哪些配置以免受到上传的大小限制？或者你有其它更好的方式？
> 修改`upload_max_filesize`，如果nginx+php-fpm还要修改nginx的`client_max_body_size`；
> 可以使用文件流的形式上传

#### 
[<svg class="octicon octicon-link" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg>](#cli)Cli

*   用PHP实现一个定时任务器？
> PCNTL扩展，`pcntl_alarm()` [参考实现](https://www.cnblogs.com/CpNice/p/4528610.html)
> swoole_timer

#### 
[<svg class="octicon octicon-link" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg>](#%E5%AE%89%E5%85%A8)安全

*   PHP中密码加密，使用什么方式加密？这种加密的优点是什么？
> `password_hash()`
> `password_hash()`使用足够强度的单向散列算法创建密码的散列（hash），来产生足够强的盐值，并且会自动进行合适的轮次。`password_hash()`是`crypt()`的一个简单封装，并且完全与现有的密码哈希兼容。

*   PHP 7.2 新增的加密方法的名称是？
> Argon2

#### 
[<svg class="octicon octicon-link" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg>](#%E5%8F%8D%E5%B0%84)反射

*   实现如下函数(PHP 7)
```php
    echo a(1, 3); //4
    echo a(3)(5); //8
    echo a(1, 2)(3, 4, 5)(6); //21
    //实现不了
    function a(){
        $sum = array_sum(func_get_args());
        return function() use($sum) {
            return $sum+=array_sum(func_get_args());
        };
    }
```

*   如何读取某函数的参数列表，以及参数的默认值。
> 通过`func_get_args()`获取参数列表，通过` func_get_arg(index)`获取参数值

*   描述下IoC （DI）的实现原理
> DI（依赖注入）是Ioc（控制反转）的一种实现方式。常见注入方式有`setter、contructor injection、property injection`。 [laravel服务容器-----深入理解控制反转（IoC）和依赖注入（DI）](https://www.cnblogs.com/lishanlei/p/7627367.html)
> DI的实现依赖于php的反射api的能力。DI容器的实现是通过反射api的能力递归分析类的依赖关系并实例化所有依赖。

### 
[<svg class="octicon octicon-link" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg>](#%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AF%87)数据库篇

*   搭建MySQL分布式，有哪些方式？
> 客户端方案或者中间代理方案

*   MySQL主从同步，和主主同步有哪些区别，以及优劣势？
> 主节点 binary log dump 线程
> 当从节点连接主节点时，主节点会创建一个log dump 线程，用于发送bin-log的内容。在读取bin-log中的操作时，此线程会对主节点上的bin-log加锁，当读取完成，甚至在发动给从节点之前，锁会被释放。


> 从节点I/O线程
> 当从节点上执行`start slave`命令之后，从节点会创建一个I/O线程用来连接主节点，请求主库中更新的bin-log。I/O线程接收到主节点binlog dump 进程发来的更新之后，保存在本地relay-log中。


> 从节点SQL线程
> SQL线程负责读取relay log中的内容，解析成具体的操作并执行，最终保证主从数据的一致性。

> 对于每一个主从连接，都需要三个进程来完成。当主节点有多个从节点时，主节点会为每一个当前连接的从节点建一个binary log dump 进程，而每个从节点都有自己的I/O进程，SQL进程。从节点用两个线程将从主库拉取更新和执行分成独立的任务，这样在执行同步数据任务的时候，不会降低读操作的性能。比如，如果从节点没有运行，此时I/O进程可以很快从主节点获取更新，尽管SQL进程还没有执行。如果在SQL进程执行之前从节点服务停止，至少I/O进程已经从主节点拉取到了最新的变更并且保存在本地relay日志中，当服务再次起来之后，就可以完成数据的同步。

> **推荐阅读**
> [[深度探索MySQL主从复制原理](https://zhuanlan.zhihu.com/p/50597960)]

*   Laravel中，多态一对多，多对多，数据库要怎么设计？比如一个关键词表tags，需要关联用户、帖子、评论、视频等表。
> tags表，主要字段tags_id,tags_name
> 关联表tags_relation，主要字段,id均为个表的主键relation_id,tags_id,video_id,post_id,comment_id,video_id

*   MySQL防止注入有哪些方式？
> 最好采用预编译语句`PreparedStatement`的方式
> mysql语句中使用`mysql_real_escape_string()`函数进行转义
> 打开php的设置项`magic_quotes_gpc=on`，将自动把用户提交对sql的查询进行转换

*   描述MySQL的注入原理？
> 通过把SQL命令插入到Web表单提交或输入域名或页面请求的查询字符串，最终达到欺骗服务器执行恶意的SQL命令

*   怎么解决数据库中常见的 N+1 效率问题
比如：
```php
    $users = SELECT * FROM `users` WHERE `gender` = 'male';
    foreach ($users as &$user)
    $user['posts'] = SELECT * FROM `posts` WHERE `user_id` = $user['id'];
``` 
> 先查出所有gender为male的用户id，再根据这些用户id去查询posts

```sql
    #查出所有用户id
    select user_id from `users` where `gender` = 'male';
    #使用in查出所有user的posts数据 
    select * from `posts` where `user_id` in(userid);
    #然后在php中按用户整理posts数据返回
```

*   哪些情况下字段允许null，哪些情况下不允许？
> 尽量设置not null
> 理由
> 含有null值的列难以进行查询优化
> 影响索引效率，使得索引、索引的统计信息以及比较运算更加复杂

*   MySQL中脏读应该怎么处理？
引申：比如京东的库存，0点多人抢购的时候库存问题？
> 解决mysql脏读的方法：1、serializable可避免脏读、不可重复读、虚读情况的发生；2、repeatable read可以避免脏读、不可重复读情况的发生；3、read committed可以避免脏读情况发生。
> 

*   如下数据库中会有哪些值

```sql
    START TRANSACTION;
    INSERT INTO `users` (`name`) VALUES('a');
    START TRANSACTION;
    INSERT INTO `users` (`name`) VALUES('b');
    START TRANSACTION;
    INSERT INTO `users` (`name`) VALUES('c');
    ROLLBACK;
    COMMIT;
    ROLLBACK;
```
> a, b
> 在一个事务没有`COMMIT`或者`ROLLBACK`时再`START TRANSACTION`，会自动提交前面的事务。

*   Elasticsearch 如何实现类似SQL的
```sql
    WHERE `id` = 12 AND `gender`  IN ('male', 'unknow’);
```

*   innodb 的数据组织方式？
> InnoDB 存储引擎以页（默认为16KB）为基本单位存储

*   B + 树的结构和插入细节？为什么主键一般都要自增？和 B 树什么区别？为什么索引要使用 B + 树不是 B 树也不是其他的平衡树？
> B + 树的结构

> M阶段B树每个节点最多有M个孩子

> 除了根节点和叶子节点外，其他每个节点至少有ceil(M/2)个孩子

> B+树的中间节点没有卫星数据的。所以同样大小的磁盘页可以容纳更多的节点元素。（这就意味着B+会更加矮胖，查询的IO次数会更少）。

> 所有查询都要查找到叶子节点，查询性能稳定。

> 所有叶子节点形成有序链表，便于范围查询。

> B树查找性能是不稳定的（如果要查找的数据分别在根节点和叶子节点，他们的性能就会不同）。但B+树的每一次都是稳定的。

>一个m阶的B+树具有如下几个特征：

> 1、有k个子树的中间节点包含有k个元素（B树中是k-1个元素），每个元素不保存数据，只用来索引，所有数据都保存在叶子节点。 

>2、所有的叶子结点中包含了全部元素的信息，及指向含这些元素记录的指针，且叶子结点本身依关键字的大小自小而大顺序链接。 

>3、所有的中间节点元素都同时存在于子节点，在子节点元素中是最大（或最小）元素。


> [为什么mysql索引要使用B+树，而不是B树，红黑树](https://segmentfault.com/a/1190000021488885)

* MySQL中存储索引用到的数据结构是B+树，B+树的查询时间跟树的高度有关，是log(n)，如果用hash存储，那么查询时间是O(1)。既然hash比B+树更快，为什么mysql用B+树来存储索引呢？

> 答：一、从内存角度上说，数据库中的索引一般时在磁盘上，数据量大的情况可能无法一次性装入内存，B+树的设计可以允许数据分批加载。

> 二、从业务场景上说，如果只选择一个数据那确实是hash更快，但是数据库中经常会选中多条这时候由于B+树索引有序，并且又有链表相连，它的查询效率比hash就快很多了。

* 为什么不用红黑树或者二叉排序树？

> 答：树的查询时间跟树的高度有关，B+树是一棵多路搜索树可以降低树的高度，提高查找效率

* 既然增加树的路数可以降低树的高度，那么无限增加树的路数是不是可以有最优的查找效率？

>答：这样会形成一个有序数组，文件系统和数据库的索引都是存在硬盘上的，并且如果数据量大的话，不一定能一次性加载到内存中。有序数组没法一次性加载进内存，这时候B+树的多路存储威力就出来了，可以每次加载B+树的一个结点，然后一步步往下找，

* 在内存中，红黑树比B树更优，但是涉及到磁盘操作B树就更优了，那么你能讲讲B+树吗？

> B+树是在B树的基础上进行改造，它的数据都在叶子结点，同时叶子结点之间还加了指针形成链表。

* 为什么B+树要这样设计？

> 答：这个跟它的使用场景有关，B+树在数据库的索引中用得比较多，数据库中select数据，不一定只选一条，很多时候会选中多条，比如按照id进行排序后选100条。如果是多条的话，B树需要做局部的中序遍历，可能要跨层访问。而B+树由于所有数据都在叶子结点不用跨层，同时由于有链表结构，只需要找到首尾，通过链表就能把所有数据取出来了。



*   常见的优化（这里我就不展开了，主要考察覆盖索引查询和最左匹配）
> 

*   `redolog/undolog/binlog` 的区别？binlog 的几种格式？说下两阶段提交？
> [必须了解的mysql三大日志-binlog、redo log和undo log]https://segmentfault.com/a/1190000023827696

> 由 binlog 和 redo log 的区别可知： binlog 日志只用于归档，只依靠 binlog 是没有 `crash-safe 能力的。但只有 redo log 也不行，因为 redo log 是 InnoDB `特有的，且日志上的记录落盘后会被覆盖掉。因此需要 binlog 和 redo log二者同时记录，才能保证当数据库发生宕机重启时，数据不会丢失。

>数据库事务四大特性中有一个是 原子性 ，具体来说就是 原子性是指对数据库的一系列操作，要么全部成功，要么全部失败，不可能出现部分成功的情况。实际上， 原子性 底层就是通过 undo log 实现的。 undo log 主要记录了数据的逻辑变化，比如一条 ` INSERT语句，对应一条 DELETE 的 undo log ，对于每个 UPDATE 语句，对应一条相反的 UPDATE 的undo log ，这样在发生错误时，就能回滚到事务之前的数据状态。同时， undo log 也是 MVCC `(多版本并发控制)实现的关键

|  | redo log | binlog |
| :-----:| :----: | :----: |
| 文件大小 | redo log 的大小是固定的。 | binlog 可通过配置参数 max_binlog_size 设置每个 binlog 文件的大小。 |
| 实现方式 | redo log 是 InnoDB 引擎层实现的，并不是所有引擎都有。 | binlog 是 Server 层实现的，所有引擎都可以使用 binlog 日志 |
| 记录方式 | redo log 采用循环写的方式记录，当写到结尾时，会回到开头循环写日志。 | binlog通过追加的方式记录，当文件大小大于给定值后，后续的日志会记录到新的文件上 |
| 适用场景 | redo log 适用于崩溃恢复(crash-safe) | binlog 适用于主从复制和数据恢复 |

    binlog日志有三种格式，分别为STATMENT、ROW和MIXED。

    在 MySQL 5.7.7之前，默认的格式是STATEMENT，MySQL 5.7.7之后，默认值是ROW。日志格式通过binlog-format指定。

    STATMENT 基于SQL语句的复制(statement-based replication, SBR)，每一条会修改数据的sql语句会记录到binlog中。 优点：不需要记录每一行的变化，减少了binlog日志量，节约了IO, 从而提高了性能； 缺点：在某些情况下会导致主从数据不一致，比如执行sysdate()、slepp()等。
    ROW 基于行的复制(row-based replication, RBR)，不记录每条sql语句的上下文信息，仅需记录哪条数据被修改了。 优点：不会出现某些特定情况下的存储过程、或function、或trigger的调用和触发无法被正确复制的问题； 缺点：会产生大量的日志，尤其是alter table的时候会让日志暴涨
    MIXED 基于STATMENT和ROW两种模式的混合复制(mixed-based replication, MBR)，一般的复制使用STATEMENT模式保存binlog，对于STATEMENT模式无法复制的操作使用ROW模式保存binlog

MySQL想要准备事务的时候会先写redolog、binlog分成两个阶段。

[MySQL两阶段提交串讲](https://zhuanlan.zhihu.com/p/343449447)

    两阶段提交的第一阶段 （prepare阶段）：写rodo-log 并将其标记为prepare状态。

    紧接着写binlog

    两阶段提交的第二阶段（commit阶段）：写bin-log 并将其标记为commit状态。

    你有没有想过这样一件事，binlog默认都是不开启的状态！

    也就是说，如果你根本不需要binlog带给你的特性（比如数据备份恢复、搭建MySQL主从集群），那你根本就用不着让MySQL写binlog，也用不着什么两阶段提交。

    只用一个redolog就够了。无论你的数据库如何crash，redolog中记录的内容总能让你MySQL内存中的数据恢复成crash之前的状态。

    所以说，两阶段提交的主要用意是：为了保证redolog和binlog数据的安全一致性。只有在这两个日志文件逻辑上高度一致了。你才能放心地使用redolog帮你将数据库中的状态恢复成crash之前的状态，使用binlog实现数据备份、恢复、以及主从复制。而两阶段提交的机制可以保证这两个日志文件的逻辑是高度一致的。没有错误、没有冲突。






*   事务隔离级别和不同级别会出现的问题，innodb 默认哪个级别？MVCC 怎么实现的？快照读和当前读有啥区别？幻读的问题怎么解决？
> 

[mysql事务和锁，一次性讲清楚](https://juejin.cn/post/6855129007336521741)

| 隔离级别 | 脏读 | 不可重复读 | 幻读 |
| :-----:| :----: | :----: | :----: |
| 未提交读（READ UNCOMMITTED） | 可能 | 可能	| 可能 | 
| 已提交读（READ COMMITTED） | 不可能 | 可能 | 可能 | 
| (默认)可重复读（REPEATABLE READ） | 不可能 | 不可能 | 可能（对InnoDB不可能） | 
| 串行化（SERIALIZABLE） | 	不可能 | 	不可能 | 	不可能 | 


MVCC实现

>在InnoDB中，每行记录实际上都包含了两个隐藏字段：事务id(trx_id)和回滚指针(roll_pointer)。

>trx_id：事务id。每次修改某行记录时，都会把该事务的事务id赋值给trx_id隐藏列。

>roll_pointer：回滚指针。每次修改某行记录时，都会把undo日志地址赋值给roll_pointer隐藏列。

> 如果数据库隔离级别是未提交读（READ UNCOMMITTED），那么读取版本链中最新版本的记录即可。如果是是串行化（SERIALIZABLE），事务之间是加锁执行的，不存在读不一致的问题。但是如果是已提交读（READ COMMITTED）或者可重复读（REPEATABLE READ），就需要遍历版本链中的每一条记录，判断该条记录是否对当前事务可见，直到找到为止(遍历完还没找到就说明记录不存在)。InnoDB通过ReadView实现了这个功能。ReadView中主要包含以下4个内容：

>* m_ids：表示在生成ReadView时当前系统中活跃的读写事务的事务id列表。
>* min_trx_id：表示在生成ReadView时当前系统中活跃的读写事务中最小的事务id，也就是m_ids中的最小值。
>* max_trx_id：表示生成ReadView时系统中应该分配给下一个事务的id值。
>* creator_trx_id：表示生成该ReadView事务的事务id。  
> 在MySQL中，READ COMMITTED和REPEATABLE READ隔离级别的的一个非常大的区别就是它们生成ReadView的时机不同。READ COMMITTED在每次读取数据前都会生成一个ReadView，这样就能保证每次都能读到其它事务已提交的数据。REPEATABLE READ 只在第一次读取数据时生成一个ReadView，这样就能保证后续读取的结果完全一致。

> 在快照读读情况下，mysql通过mvcc来避免幻读。

> 在当前读读情况下，mysql通过next-key来避免幻读。

*  主从同步流程（异步同步）
>* 主库把数据变更写入binlog文件
>* 从库I/O线程发起dump请求
>* 主库I/O线程推送binlog至从库
>* 从库I/O线程写入本地的relay log文件（与binlog格式一样）
>* 从库SQL线程读取relay log并重新串行执行一遍，得到与主库相同的数据

*   主从同步，数据库主库和从库不一致，常见有这么几种优化方案：

>1. 业务可以接受，系统不优化
>2. 强制读主，高可用主库，用缓存提高读性能
>3. 在cache里记录哪些记录发生过写请求，来路由读主还是读从

* InnoDB 内存结构包含四大核心组件
>* 缓冲池 (Buffer Pool)，可以参考沈健老师文章 [缓冲池 (buffer pool)，这次彻底懂了！！！](https://mp.weixin.qq.com/s?__biz=MjM5ODYxMDA5OQ==&mid=2651962467&idx=1&sn=899ea157b0fc6f849ec80a4d055a309b&chksm=bd2d09bf8a5a80a972a2e16a190ed7dffe03f89015ead707bdfcc5aeb8388fb278f397c125f1&scene=21#wechat_redirect)

>* 写缓冲 (Change Buffer)，可以参考沈健老师文章 [写缓冲 (change buffer)，这次彻底懂了！！！](https://mp.weixin.qq.com/s?__biz=MjM5ODYxMDA5OQ==&mid=2651962450&idx=1&sn=ce17c4da8d20ce275f75d0f2ef5e40c9&chksm=bd2d098e8a5a809834aaa07da0d7546555385543fb6d687a7cf94d183ab061cd301a76547411&scene=21#wechat_redirect)

>* 自适应哈希索引 (Adaptive Hash Index)，[可以参考沈健老师文章自适应哈希索引](https://mp.weixin.qq.com/s?__biz=MjM5ODYxMDA5OQ==&mid=2651962875&idx=1&sn=c6b3e7dc8a41609cfe070026bd27b71d&chksm=bd2d08278a5a813108b1f4116341ff31170574b9098e2708cbc212b008a1fac8dfd1ffeabc6b&scene=21#wechat_redirect)
>* 日志缓冲 (Log Buffer)，[可以参考沈健老师文章 事务已提交，数据却丢了，赶紧检查下这个配置！！！ | 数据库系列](https://mp.weixin.qq.com/s?__biz=MjM5ODYxMDA5OQ==&mid=2651962887&idx=1&sn=4806f481448b1c3ddfbbd53e732a7bb5&chksm=bd2d0bdb8a5a82cd50bc155ed2ba57f105bfd76ff78992823ed85214b5c767eef17e691a2255&scene=21#wechat_redirect)


*   explain 的 type 字段有哪些（知乎）

>* system：系统表，少量数据，往往不需要进行磁盘IO
>* const：常量连接
>* eq_ref：主键索引(primary key)或者非空唯一索引(unique not null)等值扫描
>* ref：非主键非唯一索引等值扫描
>* range：范围扫描
>* index：索引树扫描
>* ALL：全表扫描(full table scan)

*   MySQL中update语句的执行流程

> 当你执行这条命令的时候，执行器首先会让InnoDB去查找到这一行，看这一行的数据页有没有在内存中，如果有就直接返回，如果没有就在磁盘中找，再读入到内存中，最后在返回。

> 执行器拿到了引擎给的数据之后，就会把这个user_name这个属性修改为“XXX”，得到一行新的数据，然后再调用引擎接口写入这行新的数据。

> 引擎把这行新的数据更新到内存的同时也会将这个更新操作记录在redo log里，这时候redo log会处于一个准备状态，然后告知执行器已经执行完成，可以随时提交事务。

> 执行器再生成这个操作的bin log，把这个bin log写入到磁盘中。

> 最后执行器再调用引擎的提交事务接口，然后把redo log 的准备状态改成提交状态，这时候更新完成。

*   死锁什么时候会出现？应用层应该怎么做避免死锁？mysql 是怎么处理死锁的呢？

> MySQL 出现死锁的几个要素为：

>* 两个或者两个以上事务
>* 每个事务都已经持有锁并且申请新的锁
>* 锁资源同时只能被同一个事务持有或者不兼容
>* 事务之间因为持有锁和申请锁导致彼此循环等待

> 减少死锁：

>* 使用事务，不使用 lock tables 。
>* 保证没有长事务。
>* 操作完之后立即提交事务，特别是在交互式命令行中。
>* 如果在用 (SELECT ... FOR UPDATE or SELECT ... LOCK IN SHARE MODE)，尝试降低隔离级别。
>* 修改多个表或者多个行的时候，将修改的顺序保持一致。
>* 创建索引，可以使创建的锁更少。
>* 最好不要用 (SELECT ... FOR UPDATE or SELECT ... LOCK IN SHARE MODE)。
>* 如果上述都无法解决问题，那么尝试使用 lock tables t1, t2, t3 锁多张表
>* 合理的设计索引，区分度高的列放到组合索引前面，使业务 SQL 尽可能通过索引定位更少的行，减少锁竞争。
>* 调整业务逻辑 SQL 执行顺序， 避免 update/delete 长时间持有锁的 SQL 在事务前面。
>* 避免大事务，尽量将大事务拆成多个小事务来处理，小事务发生锁冲突的几率也更小。
>* 以固定的顺序访问表和行。比如两个更新数据的事务，事务 A 更新数据的顺序为 1，2;事务 B 更新数据的顺序为 2，1。这样更可能会造成死锁。
>* 在并发比较高的系统中，不要显式加锁，特别是是在事务里显式加锁。如 select … for update 语句，如果是在事务里（运行了 start transaction 或设置了autocommit 等于0）,那么就会锁定所查找到的记录。
>* 尽量按主键/索引去查找记录，范围查找增加了锁冲突的可能性，也不要利用数据库做一些额外额度计算工作。比如有的程序会用到 “select … where … order by rand();”这样的语句，由于类似这样的语句用不到索引，因此将导致整个表的数据都被锁住。
>* 优化 SQL 和表设计，减少同时占用太多资源的情况。比如说，减少连接的表，将复杂 SQL 分解为多个简单的 SQL。


> * MySQL有两种死锁处理方式：  
> 1. 等待，直到超时（innodb_lock_wait_timeout=50s）。   
> 2. 发起死锁检测，主动回滚一条事务，让其他事务继续执行（innodb_deadlock_detect=on）。  
> 3. 由于性能原因，一般都是使用死锁检测来进行处理死锁。


*  MySQL 遇到过死锁问题吗，你是如何解决的？
>排查死锁的步骤：

>查看死锁日志 show engine innodb status;  
>找出死锁 Sql  
>分析 sql 加锁情况  
>模拟死锁案发  
>分析死锁日志  
>分析死锁结果

* 常用的分库分表中间件
>sharding-jdbc  
>Mycat

*  分库分表可能遇到的问题

>* 事务问题：需要用分布式事务
>* 跨节点 Join 的问题：解决这一问题可以分两次查询实现
>* 跨节点的 count,order by,group by 以及聚合函数问题：分别在各个节点上得到结果后在应用程序端进行合并。
>* 数据迁移，容量规划，扩容等问题
>* ID 问题：数据库被切分后，不能再依赖数据库自身的主键生成机制啦，最简单可以考虑 UUID
>* 跨分片的排序分页问题（后台加大 pagesize 处理？）

*  limit 1000000 加载很慢的话，你是怎么解决的呢？
>* 方案一：如果 id 是连续的，可以这样，返回上次查询的最大记录 (偏移量)，再往下 limit   
>* 方案二：在业务允许的情况下限制页数： 建议跟业务讨论，有没有必要查这么后的分页啦。因为绝大多数用户都不会往后翻太多页。
>* 方案三：order by + 索引（id 为索引）
>* 方案四：利用延迟关联或者子查询优化超多分页场景。（先快速定位需要获取的 id 段，然后再关联）


*  InnoDB 四种事务隔离级别：

>* 读未提交 (Read Uncommitted)
>* 读提交 (Read Committed, RC)
>* 可重复读 (Repeated Read, RR)
>* 串行化 (Serializable)   

>不同事务的隔离级别，实际上是一致性与并发性的一个权衡与折衷。   
>InnoDB 使用不同的锁策略 (Locking Strategy) 来实现不同的隔离级别。

>读未提交 (Read Uncommitted)
>* 这种事务隔离级别下，select 语句不加锁。

>* 此时，可能读取到不一致的数据，即 “读脏”。这是并发最高，一致性最差的隔离级别。

>串行化 (Serializable)
>* 这种事务的隔离级别下，所有 select 语句都会被隐式的转化为 select … in share mode.

>* 这可能导致，如果有未提交的事务正在修改某些行，所有读取这些行的 select 都会被阻塞住。

>* 这是一致性最好的，但并发性最差的隔离级别。 在互联网大数据量，高并发量的场景下，几乎不会使用上述两种隔离级别。

> 可重复读 (Repeated Read, RR) 这是 InnoDB 默认的隔离级别，在 RR 下：
>* 普通的 select 使用快照读 (snapshot read)，这是一种不加锁的一致性读 (Consistent Nonlocking Read)，底层使用 MVCC 来实现；

>* 加锁的 select (select … in share mode /select … for update), update, delete 等语句，它们的锁，依赖于它们是否在唯一索引 (unique index) 上使用了唯一的查询条件 (unique search condition)，或者范围查询条件 (range-type search condition)：

>* 在唯一索引上使用唯一的查询条件，会使用记录锁 (record lock)，而不会封锁记录之间的间隔，即不会使用间隙锁 (gap lock) 与临键锁 (next-key lock)
>* 范围查询条件，会使用间隙锁与临键锁，锁住索引记录之间的范围，避免范围间插入记录，以避免产生幻影行记录，以及避免不可重复的读

> 读提交 (Read Committed, RC) 这是互联网最常用的隔离级别，在 RC 下：
>* 普通读是快照读；

>* 加锁的 select, update, delete 等语句，除了在外键约束检查 (foreign-key constraint checking) 以及重复键检查 (duplicate-key checking) 时会封锁区间，其他时刻都只使用记录锁；
>* 此时，其他事务的插入依然可以执行，就可能导致，读取到幻影记录。

*   select for update 有什么含义，会锁表还是锁行还是其他？

>select 查询语句是不会加锁的，但是 select for update 除了有查询的作用外，还会加锁呢，而且它是悲观锁哦。至于加了是行锁还是表锁，这就要看是不是用了索引 / 主键啦。 没用索引 / 主键的话就是表锁，否则就是是行锁。

*  MySQL 事务得四大特性以及实现原理
>* 原子性： 事务作为一个整体被执行，包含在其中的对数据库的操作要么全部被执行，要么都不执行。
>* 一致性： 指在事务开始之前和事务结束以后，数据不会被破坏，假如 A 账户给 B 账户转 10 块钱，不管成功与否，A 和 B 的总金额是不变的。
>* 隔离性： 多个事务并发访问时，事务之间是相互隔离的，即一个事务不影响其它事务运行效果。简言之，就是事务之间是进水不犯河水的。
>* 持久性： 表示事务完成以后，该事务对数据库所作的操作更改，将持久地保存在数据库之中。

>事务 ACID 特性的实现思想
>* 原子性：是使用 undo log 来实现的，如果事务执行过程中出错或者用户执行了 rollback，系统通过 undo log 日志返回事务开始的状态。
>* 持久性：使用 redo log 来实现，只要 redo log 日志持久化了，当系统崩溃，即可通过 redo log 把数据恢复。
>* 隔离性：通过锁以及 MVCC, 使事务相互隔离开。
>* 一致性：通过回滚、恢复，以及并发情况下的隔离性，从而实现一致性。


*   int 占多少字节？bigint 呢？int (3) 和 int (11) 有区别吗？可以往 int (3) 里存 1 亿吗？varchar 最长多少？
> int 4个字节
> bigint 8个字节
> tinyint 1个字节 smallint 2个字节 mediumint 3个字节
> int(3)和int(11)占用字节数无区别，都是4个字节。3和11表示在字段添加了`zerofill`属性后填充0之后的长度
> int(3) 取值范围 `-2^31 ~ 2^31-1`， 可以存1亿
> varchar受限mysql的行长度，行长度和其他非大型字段（如text、blob）加起来不能超过65535个字节
> 其次根据字符集的不同，GBK每个字符占用2个字节，UTF8下占用3个字节，因此分别在GBK和UTF8下的最大长度分别是`65535/2=32766`和`65535/3=21845`
> _引申_
> [为什么mysql的varchar字符长度会被经常性的设置成255？](https://blog.csdn.net/w790634493/article/details/80650611?depth_1-utm_source=distribute.pc_relevant.none-task&amp;utm_source=distribute.pc_relevant.none-task)

*   sql 的执行流程
> **建立TCP连接**
> 连接成功后会验证权限
> 半双工通信
> **查询缓存，如果命中则直接返回**
> 一个大小写敏感的哈希查找实现的
> 返回结果前再次验证权限
> **进行语法解析和预处理**
> 通过mysql关键字将语句解析，生成解析树，验证是否有错误的关键字，顺序是否正确
> 预处理器根据mysql的规则，检查语句是否合法，库表字段是否存在，并验证权限
> **进行优化转换成执行计划**
> 一条sql会有多种方式查询，选择一种执行此计划成本最小的
> **调用存储引擎的API执行查询**
> 返回结果

参考资料 [一条SQL的执行过程](https://zhuanlan.zhihu.com/p/70295845)

*   MySQL 索引使用有哪些注意事项呢？

>可以从两个维度回答这个问题：索引哪些情况会失效，索引不适合哪些场景

> * 索引哪些情况会失效

> 查询条件包含 or，会导致索引失效。

> 隐式类型转换，会导致索引失效，例如 age 字段类型是 int，我们 where age = “1”，这样就会触发隐式类型转换。

> like 通配符会导致索引失效，注意:”ABC%” 不会失效，会走 range 索引，”% ABC” 索引会失效

> 联合索引，查询时的条件列不是联合索引中的第一个列，索引失效。

> 对索引字段进行函数运算。

> 对索引列运算（如，+、-、*、/），索引失效。

> 索引字段上使用（!= 或者 < >，not in）时，会导致索引失效。

> 索引字段上使用 is null， is not null，可能导致索引失效。

> 相 join 的两个表的字符编码不同，不能命中索引，会导致笛卡尔积的循环计算

> mysql 估计使用全表扫描要比使用索引快，则不使用索引。
> * 索引不适合哪些场景

> 数据量少的不适合加索引

> 更新比较频繁的也不适合加索引

> 离散性低的字段不适合加索引（如性别）



### 
[<svg class="octicon octicon-link" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg>](#redis)Redis

**推荐阅读**

*   [[吃透了这些Redis知识点，阿里P8都问不倒你！（干货）](https://www.toutiao.com/i6681583952743891460/)]
*   [[Redis深入浅出——字符串和SDS](https://blog.csdn.net/qq193423571/article/details/81637075)]
*   [[Redis深入理解之简单动态字符串（SDS）](https://blog.csdn.net/TCJGGSDDU/article/details/81275462)]
*   [[Redis hash实现详解](https://www.jianshu.com/p/7f53f5e683cf)]
*   [[查漏补缺，Redis为什么会这么快，看完这七点你就知道了](https://www.cnblogs.com/kx33389/p/11298169.html)]
*   [[Redis设计与实现3 哈希对象（ ziplist /hashtable）](https://www.jianshu.com/p/2095df8ae4a8)]
*   [[什么是跳表？Redis为什么使用跳表来实现有序集合？](https://blog.csdn.net/ChaunceyChen/article/details/89370236)]
*   [[Redis 源码日志](https://app.yinxiang.com/shard/s3/nl/317377/a52d05dd-7bb7-4dad-af76-82e88d3eb7ca/)]

**名词解释**
`RDB：Redis DB hdfs: fsimage`
`AOF: AppendOnlyFile hdfs: edit logs`
`SDS: Simple dynamic string`
`LRU: Least recently used`

*   sds 的结构是什么？为什么要存长度？跟 c 里的字符串有什么区别？
> `Header[len,alloc,flags,free] + char buf[] + \0`
> len 已使用字节数,alloc 总字节数,flags header类型,free 未使用的字节数, char buf[] 保存字符串的数组
> 为什么要存长度:避免O(n)的复杂度获取字符串长度带来的额外开销，提升性能考虑
> **与c的字符串区别**
> sds 通过空间预分配策略和惰性空间释减少了内存操作次数
> sds 保存了字符串的长度，获取字符串长度的复杂度为O(1)
> sds 使用len来判断字符串是否结束，是二进制安全的，可保存文本或二进制数据。
> sds API安全，不会造成缓冲区溢出
> **扩容策略**
> **空间预分配**
> _`SDS_MAX_PREALLOC = 1mb（默认）`_
> 当扩容之后的长度小于`SDS_MAX_PREALLOC`时，那么会分配同样大小的未使用空间
> 当扩容之后的长度大于`SDS_MAX_PREALLOC`时，会分配`SDS_MAX_PREALLOC`的未使用空间
> **惰性空间释放策略**
> 当需要收缩时，不立即使用内存重分配来回收缩短后多出来的字节，而是使用表头的free成员将这些字节记录起来，并等待将来使用

[Redis深入理解之简单动态字符串](https://blog.csdn.net/TCJGGSDDU/article/details/81275462)

*  缓存如何保证一致性
>1. 想要提高应用的性能，可以引入「缓存」来解决

>2. 引入缓存后，需要考虑缓存和数据库一致性问题，可选的方案有：「更新数据库 + 更新缓存」、「更新数据库 + 删除缓存」
>3. 更新数据库 + 更新缓存方案，在「并发」场景下无法保证缓存和数据一致性，且存在「缓存资源浪费」和「机器性能浪费」的情况发生
>4. 在更新数据库 + 删除缓存的方案中，「先删除缓存，再更新数据库」在「并发」场景下依旧有数据不一致问题，解决方案是「延迟双删」，但这个延迟时间很难评估，所以推荐用「先更新数据库，再删除缓存」的方案
>5. 在「先更新数据库，再删除缓存」方案下，为了保证两步都成功执行，需配合「消息队列」或「订阅变更日志」的方案来做，本质是通过「重试」的方式保证数据一致性
>6. 在「先更新数据库，再删除缓存」方案下，「读写分离 + 主从库延迟」也会导致缓存和数据库不一致，缓解此问题的方案是「延迟双删」，凭借经验发送「延迟消息」到队列中，延迟删除缓存，同时也要控制主从库延迟，尽可能降低不一致发生的概率

*    用过 redis 哪些数据结构，使用场景是什么
>1. string 缓存，分布式锁，计数器，分布式系统唯一id
>2. hash 电商购物车，用户信息，商品信息等属性信息
>3. list 微博/微信信息流，消息队列，朋友圈的点赞列表、评论列表、排行榜
>4. set 抽奖，好友、关注、粉丝、点赞、感兴趣的人集合，在电商购物中，通过条件来筛选商品
>5. zset(有序集合) 热搜榜或者新闻排行榜，在直播系统中，实时排行信息包含直播间在线用户列表，各种礼物排行榜，弹幕消息（可以理解为按消息维度的消息排行榜）等信息

*   hash 怎么实现的？怎么解决 hash 冲突？除了 hashTable 还有别的吗？
> 数组+链表
> 链地址法
> 当键和值的字符串长度都小于64字节 且 键值对数量小于512个时使用
> `zipList` 否则使用`hashTable`

*   zset 怎么实现的？跳表是怎么插入的？为什么选择跳表不用其他平衡二叉树？除了跳表还有别的吗？
> HashTable+skiplist
> **插入步骤**
> 采用丢硬币的方式确定插入的level k, 然后再level1到levelk各个层按顺序插入元素
> **丢硬币确定K**
> 丢硬币实验，如遇到正面，继续丢，遇到反面，则停止
> c代码

```c
  int random_level()  
    {  
        K = 1;  
        while (random(0,1))  
            K++;  
        return K;  
    }   
```
> **为什么选择跳表而不用其他平衡二叉树**
> 范围查找更简单
> 插入和删除操作可能导致子树的调整，逻辑比较复杂。skiplist只需要修改相邻两个节点指针，简单快速
> skiplist比树占用更少的内存
> skiplist更容易实现
> ziplist、dict
> 推荐阅读

*   [[Redis 为什么用跳表而不用平衡树？](https://juejin.im/post/57fa935b0e3dd90057c50fbc)]

*   为什么 redis 用跳表？
> 因为redis中的zset数据结构需要支持按区间查找所有元素，在跳表中，只要定位到两个区间端点在最底层级的位置，然后按顺序遍历元素就可以了，非常高效。而红黑树只能定位到端点后，再从首位置开始每次都要查找后继节点，相对来说比较耗时。此外，跳表实现起来很容易且易读，红黑树实现起来相对困难

*   rehash 过程？会主动 rehash 吗？
> **过程**
> 创建ht[1]并分配至少2倍于ht[0] table的空间
> 将ht[0] table中的所有键值对迁移到ht[1] table
> 将ht[0]数据清空，并将ht[1]替换为新的ht[0]
> 会主动rehash，redis会在定时任务中主动rehash
> 为什么要rehash?
> 减少hash冲突，防止链表长度过长影响查找性能

*   用 redis 可以实现队列吗？有什么优点和缺点？
> 可以利用`list/zset`实现队列效果

*   用 redis 怎么实现一个延时队列？
> `zset`

*   rdb 和 aof 过程？rdb 为什么可以用创建子进程的方式进行？（这里考察一个 cow）这两种持久化方式会丢数据吗？
> rdb过程
> 在指定的时间间隔内将内存中的数据集快照写入磁盘
> aof过程
> 将每一个收到的写命令都通过write函数追加到日志文件中
> rdb的三种触发机制`save、bgsave、自动化`。子进程方式主要是利用了写时复制技术，子进程共享父进程的虚拟空间结构和物理空间，当有发生更改行为时，再为子进程相应的分配物理空间
> rdb所持久化的数据是fork发生时的数据，在这样的条件下进行持久化数据，如果因为某些情况宕机，则会丢失一段时间数据。aof everysec模式可能会丢失1秒数据

*   redis 为什么快？（主要考察一个 IO 多路复用和单线程不加锁）
> redis都是对内存操作，速度极快(QPS 10w+)
> 单线程避免了多线程的同步和加锁、上下文切换消耗的cpu时间
> 单线程天然支持原子操作，代码写起来更简单
> IO多路复用技术，利用Linux的epoll函数，一个线程可以管理多个socket连接

*   一致性哈希是什么？节点较少时数据分布不均匀怎么办？
> 一致性哈希是指能够在Hash输出空间发生变化时，引起最小的变动。
> 节点较少时可采用虚拟节点来解决不均匀的问题

*   简单说下几种 key 的淘汰策略，redis 里的 lru 算法，什么时候会触发？实现细节是什么？怎么保证淘汰合理的 key？
> **几种策略**
> noeviction(默认策略)：对于写请求不再提供服务，直接返回错误（DEL请求和部分特殊请求除外）
> allkeys-lru：从所有key中使用LRU算法进行淘汰
> volatile-lru：从设置了过期时间的key中使用LRU算法进行淘汰
> allkeys-random：从所有key中随机淘汰数据
> volatile-random：从设置了过期时间的key中随机淘汰
> volatile-ttl：在设置了过期时间的key中，根据key的过期时间进行淘汰，越早过期的越优先被淘汰
> LRU: 是一种缓存置换算法。即在缓存有限的情况下，如果有新的数据需要加载进缓存，则需要将最不可能被继续访问的缓存剔除掉
> **何时触发**
> 当redis已使用的内存超过配置maxmemory的值时触发
> **实现细节**
> edis会基于server.maxmemory_samples配置选取固定数目的key，然后比较它们的lru访问时间，然后淘汰最近最久没有访问的key，maxmemory_samples的值越大，Redis的近似LRU算法就越接近于严格LRU算法，但是相应消耗也变高，对性能有一定影响，样本值默认为5。
> **推荐阅读**
> 
> *   [[LRU原理和Redis实现——一个今日头条的面试题](https://zhuanlan.zhihu.com/p/34133067)]

*   lua 脚本的作用是什么？
> 原子性操作
> 减少网络开销
> 可移植
> 代码复用
> **推荐阅读**
> 
> *   [[如何优雅地在Redis中使用Lua](https://cloud.tencent.com/developer/article/1420672)]

*   缓存击穿 / 穿透 / 雪崩的处理策略
> **缓存击穿**
> 指热点key的失效，导致大量请求穿破缓存，打到数据库，造成数据压力过大
> 处理策略
> 设置热点数据永不过期
> **缓存穿透**
> 指频繁请求一个数据库不存在key，造成大量请求直接打倒数据库，导致数据库压力过大甚至崩溃
> 处理策略
> 缓存空值
> **缓存雪崩**
> 指在某一个时间，缓存集中失效
> 处理策略
> 缓存时间加入随机数

### 
[<svg class="octicon octicon-link" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg>](#nginx)Nginx

*   LVS 和 Nginx 分别作用在 osi 哪一层？
*   负载均衡算法

### 
[<svg class="octicon octicon-link" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg>](#%E5%89%8D%E7%AB%AF%E7%AF%87)前端篇

*   描述XSS注入原理，以及如何防止？
> XSS又叫CSS (Cross Site Script) ，跨站脚本攻击。它指的是恶意攻击者往Web页面里插入恶意html代码，当用户浏览该页之时，嵌入其中Web里面的html代码会被执行，从而达到恶意攻击用户的特殊目的。
> **防范**
> 不相信任任何用户的输入，对每个用户的输入都做严格检查，过滤，在输出的时候，对某些特殊字符进行转义，替换等

*   描述HTML 5中新增的 EventSource 的功能和应用场景？

#### 
[<svg class="octicon octicon-link" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg>](#es-6)ES 6

*   ES 6中的`Promise`对象是做什么的？
*   解释ES 6中`async、await`的使用场景？
*   ES 6中 遍历器`Iterator`怎么写，其作用是什么？
*   回调地狱(`callback hell`) 如何使用 遍历器`Iterator`实现，提示：Thunk
*   写出下面代码执行后输出的内容

```javascript
    var p1 = new Promise(resolve =>  {
        console.log(1);
        resolve(2);
    })
    let p2 = new Promise(resolve =>  {
        console.log(3);
        resolve(p1);
    });
    p1.then(re =>  {
        console.log(re);
    });
    p2.then(re =>  {
        console.log(re);
    });
```

#### 
[<svg class="octicon octicon-link" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg>](#vue)Vue

*   vue 和 angularJS 中检测脏数据的原理有什么区别？
*   vue中，vuex的主要作用是什么？
*   vue中 data 和computed 有什么区别？
```javascript
    {
        computed: {
            now() {
                return new Date();
            }
        }
    }
```

*   上面的now变量，是否能够在每次调用时得到当前时间？
*   vuex中mutations 和actions 有什么区别？
*   vuex中如何在外部（可以理解为任意一段&lt;script&gt;中）设置变量的值，以及如何调用mutations

### 
[<svg class="octicon octicon-link" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg>](#%E9%80%9A%E8%AE%AF%E5%8D%8F%E8%AE%AE%E7%AF%87)通讯协议篇

*   详细描述 HTTPS（SSL）工作原理？
> 首先使用非对称加密方式完成握手，生成并传输后续加密内容用的密钥，握手成功后使用密钥采用对称加密方式进行数据传输

*   服务器使用PHP时，客户端的IP能伪造吗？如果能，列出伪造方法；如果不能，说明原因？
> PHP获取客户单ip主要通过
> `HTTP_CLIENT_IP` 存在于http请求的header
> `HTTP_X_FORWARDED_FOR` 请求转发路径，客户端IP，代理1IP，代理2IP
> `HTTP_X_REAL_IP` 这个用得比较少
> 以上三个都是从http头获取的，并不可靠，可伪造
> 可通过curl方式设置http头
> `REMOTE_ADDR` 是直接从TCP中获取的IP，基本不会被伪造
> 参考资料 [PHP正确获取客户端的IP](https://www.cnblogs.com/lushaoyan/p/11088213.html)

*   描述域名劫持的各种方法，为什么HTTPS不能被劫持？
> 劫持方法
> 假扮域名注册人和域名注册商通信
> 是伪造域名注册人在注册商处的账户信息
> 是伪造域名注册人的域名转移请求
> 是直接进行一次域名转移请求
> 是修改域名的DNS记录
> 严格来说HTTPS也可能会被劫持，证书文件被篡改或信任了不安全的证书，同样会被中间人黑客冒用身份，进行劫持

*   描述HTTP协议是什么，以及`HTTP 2` 和 `HTTP 1.1` 有什么区别？
> HTTP协议是工作于应用层基于TCP/IP通信协议的超文本传输协议。
> 区别
> 1、多路复用，一个连接并发处理多个请求
> 2、数据压缩，使用HPACK算法对header的数据进行压缩
> 3、服务器推送，可通过开启nginx/apache相关配置支持

*   详细描述IP协议、TCP协议，以及UDP协议与它们的区别。
> 区别
> IP工作于网络互联层，TCP、UDP工作于传输层
> TCP（`Transmission Control Protocol`）面向连接、传输可靠（保证数据正确性）、有序（保证数据顺序）、传输大量数据（流模式）、速度慢、对系统资源的要求多，程序结构较复杂，每一条TCP连接只能是点到点的，TCP首部开销20字节。
> UDP（`User Data Protocol`）面向非连接 、传输不可靠（可能丢包）、无序、传输少量数据（数据报模式）、速度快，对系统资源的要求少，程序结构较简单 ，UDP支持一对一，一对多，多对一和多对多的交互通信，UDP的首部开销小，只有8个字节。

*   TCP协议中，最大传输单元MTU一般最大是多少，在TCP协议中，如果一个数据被分割成多个包，这些包结构中什么字段会被标记相同。
> 1500
> ID

*   UDP分包和TCP分包会有哪些区别？
> 

*   HTTP协议中 `Transfer-Encoding: Chunked` 适用于哪些应用场景，这个与使用 `Content-Length: xxx` 在收到的报文包上有哪些区别？
> `Transfer-Encoding: Chunked` 允许HTTP由网页服务器发送给客户端应用（ 通常是网页浏览器）的数据可以分成多个部分
> **`Transfer-Encoding: Chunked` 适用场景**
> 数据由后台动态计算，无法计算准确获取需要传输的数据长度时。具体场景如：
> **报文包的区别**
> `Transfer-Encoding: Chunked`， 将数据进行分块编码传输，每个分块包含十六进制的长度值和数据，长度值独占一行，长度不包括它结尾的 `CRLF（\r\n）`，也不包括分块数据结尾的 `CRLF`。最后一个分块长度值必须为 0，对应的分块数据没有内容，表示实体结束。
> 常常会在头部增加一个类似`Trailder:xxx`，用以指定末尾还会传递一个 xxx 的拖挂首部，比如数据的md5值。
> 如
```
b\r\n
01234567890\r\n

0\r\n
\r\n


xxx:sejfdijfejsljfeoij24jsjdfesljf
\r\n
```
> `Content-Length: xxx`, 数据包为完整的数据，长度和设置的值完全一致

### 
[<svg class="octicon octicon-link" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg>](#%E5%88%86%E5%B8%83%E5%BC%8F%E7%AF%87)分布式篇

*   描述`epoll`和`poll`、`select`的区别，为什么`epoll`会具备性能优势？
> **区别**
> 支持一个进程所能打开的最大连接数（epoll、epoll有数量限制，select无）
> FD剧增后带来的IO效率问题(poll,select对连接进行线性遍历，epoll根据每个fd上的callback函数实现，只有活跃的socket才会主动调用callback)
> 消息传递方式（poll、select核需要将消息传递到用户空间，都需要内核拷贝动作，epoll通过内核和用户空间共享一块内存来实现）
> **epoll性能优势**
> 减少了用户态和内核态之间的文件句柄拷贝；
> 减少了对可读可写文件句柄的遍历。

*   描述下惊群的原因？有什么有效的方法可以避免惊群？
> 高并发环境下，多个线程/进程同时在等待一个事件结束或完成，当这个事件完成时，多个进程/线程被唤醒，但只有一个进程或者线程进行相应处理，其他进程或线程响应失败。
> 加锁

*   什么是Hash一致性，这个方法主要运用在什么场景？
> 一致性Hash算法（`Consistent Hashing`）是一种hash算法，它能够在Hash输出空间发生变化时，引起最小的变动。
> 首先将目标值（如服务器计算机名称或者ip，在一定的空间内是唯一的）hash后与`2^32`取模获得一个整数值（一定小于2^32），这个整数值必分布在由0~2^32内的整数构成的hash环上，由此确定节点位置。
> 接下来，使用相同的方法计算出将要存储的数据key，并确定该数据再环上的位置，从该位置顺时针寻找最近的节点位置，将数据存放在该节点。
> 删除某载体节点时（载体发生故障），被删的载体节点上的数据将同样按照顺时针顺序寻找下一个载体节点，将数据迁移至该节点。
> 新增载体节点时（负载新增载体），那么在新增载体节点和逆时针方向最近的载体节点位置之间的数据将迁移到这台新增的载体节点。
> 可以看出，新增和删除节点对于整个数据环境影响很小，只会影响附近的数据的迁移
> 在节点很少的情况下，容易因为节点分布不均匀，导致某一节点负载增高，有崩溃的风险，从而引发雪崩效应，所有载体节点崩溃。
> 此时，我们可以将节点虚拟成多个节点，针对一个真实节点计算出多个虚拟的节点位置，尽可能将节点均匀分布在hash环上。
> 缓存集群场景

*   设计一个多重缓存的拓扑结构
> 

*   IO 多路复用是什么？有哪些 api？
> IO多路复用是同时监视多个文件描述符（FD）的读写就绪状况，这样多个文件描述符的I/O操作都能在一个线程内并发交替地顺序完成
> api : seelct、poll、epoll

*   select 和 epoll 的区别？水平触发和边缘触发的区别是啥？使用的时候需要注意什么？
> 区别
> select 无差别轮询所有FD，找出发生io读写的FD进行操作。 时间复杂度为O（n）。有最大fd限制为32/1024,64/2048。同时维护一个用来存放大量fd的数据结构，需要比较大的内存来支持用户态和内核态之间的拷贝动作。
> poll 无差别轮询。采用链表存储FD。
> epoll 非轮询，只有活跃的fd才会调用callback函数去操作。时间复杂度为O（1）。有最大FD上限为最大可以打开文件的数目（1GB内存的机器上大约是10万左右）。通过mmap让内核态和用户态空间共享一块内存来实现传递，减少不必要的拷贝动作。采用红黑树和链表存储FD。
> 水平触发（`LT`）是指FD在报告后，没有被处理，下次poll时会再次报告该fd
> 边缘触发（`ET`）是每个FD只报告一次，直到该FD出现第二次可读写事件之前都不会再报告，无论FD中是否还有数据可读写。
> 需要注意的是在ET模式下，read一个FD的时候一定要把它的buffer读光，也就是说一直读到read返回值小于请求值，或者遇到`EAGAIN`错误。
> 可通过`cat /proc/sys/fs/file-max`查看最大可打开文件的数目

*   epoll 储存描述符的数据结构是什么？
> 红黑树和链表

*   select 有描述符限制吗？是多少？
> 有，默认1024，可通过修改头文件重新编译内核来修改这个限制

_**关于IO多路复用，参考资料**_
[[彻底搞懂epoll高效运行的原理](https://app.yinxiang.com/shard/s3/nl/317377/65b1482f-1df8-4674-8b7b-896c25fe8f4c/)]
[[I/O多路复用技术(multiplexing)是什么？](https://www.zhihu.com/question/28594409)]
[[漫谈五种IO模型（主讲IO多路复用）](https://www.jianshu.com/p/6a6845464770)]
[[select、poll、epoll之间的区别](https://www.cnblogs.com/aspirant/p/9166944.html)]

*   进程 / 线程 / 协程区别？go 和 swoole 的协程实现有啥区别？
> **进程**
> 应用程序启动的实例
> **线程**
> 属于进程，是程序的执行者
> 一个进程至少包含一个主线程，也可以由更多的子线程
> 线程有两种调度策略，分时调度和抢占式调度
> **协程**
> 轻量级线程，创建、切换、挂起、销毁均为内存操作
> 协程是属于线程，协程是在线程里执行的
> 用户手动切换，所以又叫用户空间线程
> 协作式调度
> **swoole 协程**
> 协程客户端必须在协程的上下文环境中使用
> 协程调度器是单线程的，无法利用多核CPU，同一时间只有一个在调度
> 不允许多个协程同时读取同一个socket资源
> **go 协程**
> 协程调度器是多线程的，可利用多核CPU，同一时间可能会有多个协程在执行
> 允许多个协程同时读取同一个socket资源
> 原生支持协程，不需要声明协程环境
> 通过GPM调度模型实现

*   swoole 协程的原理？
> swoole为用户的每个请求创建一个协程，当在执行某个协程代码的过程中发现这行代码遇到了`Co::sleep()`或者产生了IO操作，swoole将会把这个相关的Fd放到EventLoop中，然后让出这个协程的CPU给其他协程使用，即挂起(`yield`)，在该Fd相关操作有结果了就继续执行这个协程，即恢复(`resume`)，所有操作完成后，调用end方法返回结果，并销毁此协程
> 协程适合IO密集型应用，因为协程在IO阻塞时会自动调度，减少IO阻塞导致的时间损失，提高了效率
> [Swoole 实现协程基本概念和底层原理](https://zhuanlan.zhihu.com/p/96471009)

### 
[<svg class="octicon octicon-link" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg>](#%E7%BB%BC%E5%90%88%E7%AF%87)综合篇

*   描述OAuth2的工作原理？
> 

*   列出几个中文分词工具？
> Jieba, SnowNLP, PkuSeg, THULAC, HanLP

*   git 放弃未提交的文件有哪些方法？
> git clean -fdx
> git reset
> git checkout .

*   git删除远程分支、Tag有什么方法？
> git push origin --delete [branch_name]

*   git覆盖远程仓库有什么办法？
> git push -u origin [branch_name]

*   CentOS 下安装php扩展有哪些方法？
> yum
> pecl
> 源码编译

*   布隆过滤器，什么时候用？优点是什么？
> 在海量数据中寻找某个别数据时可采用

### 
[<svg class="octicon octicon-link" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg>](#%E7%AE%97%E6%B3%95)算法

*   leetcode easy 级别的题目
*   排序
*   聚类
*   列表搜索
*   图表搜索

**推荐阅读**
[[必学十大经典排序算法，看这篇就够了(附完整代码/动图/优质文章)(修订版)](https://mp.weixin.qq.com/s/IAZnN00i65Ad3BicZy5kzQ)][php版本](https://codeantenna.com/a/LAyfFxnSUh)
![](https://mmbiz.qpic.cn/mmbiz_png/gsQM61GSzIMLb3kBhQibib6HpVZIdyA3icibVsahXIq2TkjOBESPLYKgRydvROy5PyPTOVXiaJHuqI0OasGEiaGbsfXQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)
### 
[<svg class="octicon octicon-link" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg>](#%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84)数据结构

*   什么是HashMap？
> [[用漫画告诉你什么是HashMap](https://zhuanlan.zhihu.com/p/78079598)]

*   树
*   栈
*   堆
*   数组
*   列表
*   队列

### 
[<svg class="octicon octicon-link" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg>](#%E5%85%B6%E4%BB%96)其他

*   硬盘如何储存数据的？
> [视频：你的硬盘是如何存储数据的？](https://sspai.com/post/55277)